{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "5lp8nnuksfi1n6zuz0vfrk",
        "toc": true,
        "id": "v0XKgFOjD63t"
      },
      "source": [
        "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Баланс-классов\" data-toc-modified-id=\"Баланс-классов-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Баланс классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изменение-весов-классов\" data-toc-modified-id=\"Изменение-весов-классов-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Изменение весов классов</a></span></li><li><span><a href=\"#Ресемплирование-с-уменьшением-класса-0\" data-toc-modified-id=\"Ресемплирование-с-уменьшением-класса-0-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Ресемплирование с уменьшением класса 0</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#Классификатор-LogisticRegression\" data-toc-modified-id=\"Классификатор-LogisticRegression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Классификатор LogisticRegression</a></span></li><li><span><a href=\"#Классификатор-DecisionTreeClassifier\" data-toc-modified-id=\"Классификатор-DecisionTreeClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Классификатор DecisionTreeClassifier</a></span></li><li><span><a href=\"#Классификатор-CatBoostClassifier\" data-toc-modified-id=\"Классификатор-CatBoostClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Классификатор CatBoostClassifier</a></span></li><li><span><a href=\"#Классификатор-SGDClassifier\" data-toc-modified-id=\"Классификатор-SGDClassifier-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Классификатор SGDClassifier</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Итоговый-вывод\" data-toc-modified-id=\"Итоговый-вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Итоговый вывод</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "2tcbs1rv39n5gwrh23nyt2",
        "id": "MkzAaZngD63u"
      },
      "source": [
        "# Проект для «Викишоп»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "9iorlsf0mh8jpo5btiqnym",
        "id": "cylf6M2iD63v"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели. \n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "nyxrkqi8qhnol3gen6a07",
        "id": "kUVQsb_lD63w"
      },
      "source": [
        "Код выполнялся в Яндекс.Облаке в Data Sphere с бесплатным тарифом на 4000р на 2 месяца, т.к. тренажер вылетал в Яндекс.Практикум. Ячейку ниже можно закомментировать, если не нужна."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "z2puzshvg7j2yw5iv5sxoh",
        "id": "tWWoJqogD63y"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "r93r5690tybeg6qwtrkijg",
        "id": "mT61I2ivD63y",
        "outputId": "7dc50552-fb51-4f43-871f-517548443022"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jupyter/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "rtn1sx0ogahdnt46iwpkf",
        "id": "YvzGS7c7D63z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
        "except:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/toxic_comments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "m9eugn13kjmiwdpbb04u6a",
        "id": "0KeUeoQGD630",
        "outputId": "db15545c-2ea0-4407-b662-22e8fd88f93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            "text     159571 non-null object\n",
            "toxic    159571 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "w1r054n7dtse5bpaj3jeg8",
        "id": "0JLmUqoPD630",
        "outputId": "2c3a621f-1195-4872-d713-54a63e23364c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "n4vfnultgmccx1wwiff14p",
        "id": "XsqJNDy1D630",
        "outputId": "3ff0e681-979f-427c-a300-b08476f76e2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    143346\n",
              "1     16225\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "8.834884437596301"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(df['toxic'].value_counts())\n",
        "class_ratio = df['toxic'].value_counts()[0] / df['toxic'].value_counts()[1]\n",
        "class_ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "zrqj4erln8lwv5r7lnti",
        "id": "f0PAUjDaD631"
      },
      "source": [
        "Классы несбалансированы. Отношение 1:8.83. Проведем поиск лучшего способа балансировки и сравним качество.\n",
        "\n",
        "- Изменение весов в модели обучения\n",
        "- Ресемплирование с уменьшением класса 0\n",
        "\n",
        "Ресемплирование с увеличением класса 1 не будем использовать из-за громоздкого набора данных.\n",
        "\n",
        "Подготовим признаки и целевой признак перед обучением."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "oh4j4poookaschwyzpmg19",
        "id": "C7X2RslsD631"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "v1dd33eqh1h2xcfajlue",
        "id": "jeZFdHkzD632",
        "outputId": "69e5ab20-7ed3-46da-b5e7-7f824a51d9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 7.19 s, sys: 128 ms, total: 7.32 s\n",
            "Wall time: 7.29 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "df['text'] = df['text'].map(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "9re7a9hv39foswkz0e5tal",
        "id": "Aja0UFvRD632",
        "outputId": "f516a2a8-4e0e-447c-8495-d336e70180b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         explanation why the edits made under my userna...\n",
              "1         d aww he matches this background colour i am s...\n",
              "2         hey man i am really not trying to edit war it ...\n",
              "3         more i cannot make any real suggestions on imp...\n",
              "4         you sir are my hero any chance you remember wh...\n",
              "                                ...                        \n",
              "159566    and for the second time of asking when your vi...\n",
              "159567    you should be ashamed of yourself that is a ho...\n",
              "159568    spitzer umm theres no actual article for prost...\n",
              "159569    and it looks like it was actually you who put ...\n",
              "159570    and i really do not think you understand i cam...\n",
              "Name: text, Length: 159571, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "4au343d6uifzytgtpdrti",
        "id": "Po-NaaCeD632"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "xnsfthxfw0s03fgpksz6v4j",
        "id": "TD9G55pfD633",
        "outputId": "f3aa7d6a-2384-478e-9647-24a0b421b648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 14min 41s, sys: 1min 27s, total: 16min 8s\n",
            "Wall time: 16min 5s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'explanation why the edits make under my username hardcore metallica fan be revert they be not vandalism just closure on some gas after i vote at new york doll fac and please do not remove the template from the talk page since i be retire now 89 205 38 27'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df['text'] = df['text'].map(lambda x:[lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(x)])\\\n",
        "    .map(lambda x:' '.join(str(e) for e in x))\n",
        "\n",
        "df['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "initj5i8nennelcusszy",
        "id": "Eh25DZuDD633",
        "outputId": "4eb257ea-54ae-47c7-d0bc-87dee44a63e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    explanation why the edits make under my userna...\n",
              "1    d aww he match this background colour i be see...\n",
              "2    hey man i be really not try to edit war it jus...\n",
              "3    more i can not make any real suggestion on imp...\n",
              "4    you sir be my hero any chance you remember wha...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'].head() #лемматизация проведена"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "sp4uh6e3rh0vno0p6hgur",
        "id": "Y6b5YnmrD634"
      },
      "source": [
        "Разобьем выборку по отношению 60/20/20. Уменьшим количество кроссвалидаций до 3 из-за размера выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "m80ans65hzbps1akmyeuc",
        "id": "1sLO92h4D634",
        "outputId": "80243af2-2c9d-418d-b153-f267eb761865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(111699, 1)\n",
            "(47872, 1)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('toxic', axis=1)\n",
        "y = df['toxic']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=23052022)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "l8jgodr0t9gq1irevuph",
        "id": "DsIcMtEID635"
      },
      "outputs": [],
      "source": [
        "cv_counts = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "g7zi3l0bmg469iwmz4zki8",
        "id": "v1T2F2wcD636",
        "outputId": "2b5ce512-58c8-4b7e-a2b3-d09ebf2f49c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
            "0.7740095524469972\n",
            "CPU times: user 1.44 s, sys: 1.56 s, total: 3 s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "lr_pipe = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, use_idf=1,\n",
        "                                              smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
        "                    ('clf', LogisticRegression(random_state=12345))])\n",
        "\n",
        "params = {'clf__C': [0.1, 1, 10],\n",
        "          'clf__class_weight': ['balanced', None]}\n",
        "\n",
        "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=2, scoring='f1', n_jobs=-1, refit=False)\n",
        "lr_grid.fit(X_train['text'], y_train)\n",
        "lr_best_paramms = lr_grid.best_params_\n",
        "\n",
        "print(lr_best_paramms)\n",
        "print(lr_grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "y0915zv3b7st0p4h561aur",
        "id": "edAuaUM9D63-"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "zdsb2zcjv8d4fj1q91o05",
        "id": "63UQX8hlD63-"
      },
      "source": [
        "Для обучения выберем следующие модели:\n",
        "\n",
        "- LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "tqjeqtd77hdkd6rmblq6q8",
        "id": "fgm2JQXKD63-"
      },
      "source": [
        "### LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "1v6xnv2ufafqze8j7r04cf",
        "id": "NmzbDxD_D63-",
        "outputId": "5a40c40f-714e-4f8d-8f48-9bd40f778b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'clf__learning_rate': 0.25, 'clf__max_depth': -1, 'clf__n_estimators': 100}\n",
            "0.7577436446515378\n",
            "CPU times: user 2.2 s, sys: 3.76 s, total: 5.96 s\n",
            "Wall time: 3min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "lgb_pipe = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
        "    ('clf', LGBMClassifier(random_state=23052022))])\n",
        "\n",
        "params = {\n",
        "  'clf__n_estimators': [100],\n",
        "  'clf__learning_rate': [0.15, 0.25],\n",
        "  'clf__max_depth': [8, 10, -1]}\n",
        "\n",
        "\n",
        "\n",
        "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=params, cv=2, scoring='f1', n_jobs=-1, refit=False)\n",
        "lgb_grid.fit(X_train['text'], y_train)\n",
        "lgb_best_params = lgb_grid.best_params_\n",
        "\n",
        "print(lgb_best_params)\n",
        "print(lgb_grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "y07ckyxgh5nspjjhu6urbf",
        "id": "FHtGErTyD63_"
      },
      "outputs": [],
      "source": [
        "vectorize = TfidfVectorizer(ngram_range=(1,2),\n",
        "               min_df=2, max_df=0.9, use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "plydignz5neidg01jnq2v",
        "id": "Ydkx3HpGD63_"
      },
      "outputs": [],
      "source": [
        "X_train = vectorize.fit_transform(X_train['text'])\n",
        "X_test = vectorize.transform(X_test['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "rc4h51yaqioldluiuag8p",
        "id": "UdetUaoTD63_",
        "outputId": "5aa3998d-e6d9-4c92-833f-6a864336732d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=12345, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_m = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
        "lr_m.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "gc3xruhg75f40m0ll3itri",
        "id": "vZNTn6WVD63_",
        "outputId": "adb0775a-bbd4-4da0-8931-166c2dda43b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.25, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=12345, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgb_m = LGBMClassifier(learning_rate=0.25, max_depth=-1, n_estimators=100, random_state = 12345)\n",
        "lgb_m.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "xy79jn4mjzp6xpd9fpjgbw",
        "id": "If76gmujD63_"
      },
      "outputs": [],
      "source": [
        "def scoring(fitted_model):\n",
        "    test_pred = fitted_model.predict(X_test)\n",
        "    test_f1 = f1_score(y_test, test_pred)\n",
        "    \n",
        "    print('F1 on test: {:.3f}'.format(test_f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "ja5z0c9b70a8kr7pbsst7d",
        "id": "SYu91HcZD64A",
        "outputId": "b6f6b996-3014-438a-fee5-d4512e5f1bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 on test: 0.786\n"
          ]
        }
      ],
      "source": [
        "scoring(lr_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellId": "b51wweapcafs09wuv2zub",
        "id": "yOMInPDgD64A",
        "outputId": "d3e0ac7a-edfa-4c60-ddb2-f67802956280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 on test: 0.764\n"
          ]
        }
      ],
      "source": [
        "scoring(lgb_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "8e2zrv29jm730va18r4uj",
        "id": "inyOEdabD64D"
      },
      "source": [
        "### Вывод\n",
        "К тестовому набору данных перейдут LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "1in251vd1q13q8yv23ouo6",
        "id": "NI1Rrbq6D64E"
      },
      "source": [
        "## Итоговый вывод\n",
        "В ходе работы над проектом было сделано:\n",
        "\n",
        "- Подготовленны данные обучения на моделях.\n",
        "- Выбран способ баланса классов и поделены данные на обучающую, валидационную и тестовою выборку.\n",
        "- Обучены модели и выбраны лучшие из них на валидационной выборке.\n",
        "- Показаны параметры качества моделей.\n",
        "\n",
        "Исходные данные обладают большим количеством признаков. Созданных столбцов больше, чем записей данных. Так как TF-IDF превращают текст в численные значения, лучшими моделями стали LogisticRegression и SGDClassifier. CatBoostClassifier может показать себя очень хорошо при долгом обучении на данных. В ходе тестов данный классификатор мог обучатся до 5 часов.\n",
        "\n",
        "На тестовой выбоке по метрике F1 лучше всего себя показал LogisticRegression всего на 0.09. Данная модель обладает больними показателями Precision и Accuracy. Это говорит нам, что токсичные комментарии находятся лучше.\n",
        "\n",
        "SGDClassifier показал себя лучше в ROC AUC и Recall метриках. Модель способна обработать больше записей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "hkhe7bq4qvhdjiyfpd5id",
        "id": "42xRIgTVD64F"
      },
      "source": [
        "## Чек-лист проверки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cellId": "6k2e3qwbi1ywhds29s9w",
        "id": "k4kUmWVsD64F"
      },
      "source": [
        "- [x]  Jupyter Notebook открыт\n",
        "- [x]  Весь код выполняется без ошибок\n",
        "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
        "- [x]  Данные загружены и подготовлены\n",
        "- [x]  Модели обучены\n",
        "- [x]  Значение метрики *F1* не меньше 0.75\n",
        "- [x]  Выводы написаны"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 50,
        "start_time": "2022-05-23T14:37:06.138Z"
      },
      {
        "duration": 84,
        "start_time": "2022-05-24T15:07:06.494Z"
      },
      {
        "duration": 6712,
        "start_time": "2022-05-24T15:07:06.579Z"
      },
      {
        "duration": 6577,
        "start_time": "2022-05-24T15:07:13.300Z"
      },
      {
        "duration": 106,
        "start_time": "2022-05-24T15:07:19.879Z"
      },
      {
        "duration": 104,
        "start_time": "2022-05-24T15:07:19.987Z"
      },
      {
        "duration": 305,
        "start_time": "2022-05-24T15:07:20.093Z"
      },
      {
        "duration": 575200,
        "start_time": "2022-05-24T15:07:20.488Z"
      },
      {
        "duration": 100,
        "start_time": "2022-05-24T15:16:55.694Z"
      },
      {
        "duration": 18,
        "start_time": "2022-05-24T15:27:22.277Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "notebookId": "4f9d91d4-e19f-46e5-af09-0fdbfca0701d",
    "notebookPath": "12_ wikishop_last_review_last_v2.ipynb",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "302.391px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "fe3663ac-1d5f-458d-8d89-2df09be50987.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}